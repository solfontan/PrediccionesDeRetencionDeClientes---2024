{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/processed/Churn_Modelling.csv')\n",
    "\n",
    "df['is_male'] = df['Gender'].replace({'Female': 0, 'Male' : 1})\n",
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Gender'], inplace=True)\n",
    "\n",
    "X = df.drop(columns='Exited')\n",
    "y = df['Exited']\n",
    "\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "variables_sin_modificacion =  df[[ 'HasCrCard', 'IsActiveMember', 'is_male']]\n",
    "categorical_features = ['Geography']\n",
    "\n",
    "# Definir transformadores para características numéricas y categóricas\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Crear un ColumnTransformer para aplicar transformaciones a diferentes columnas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Crear el pipeline con el preprocesador\n",
    "pipeline = make_pipeline(preprocessor)\n",
    "# Aplicar el preprocesador a los datos\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Obtener los nombres de las columnas después de aplicar OneHotEncoder\n",
    "encoded_categorical_columns = preprocessor.named_transformers_['cat']\\\n",
    "    .get_feature_names_out(input_features=categorical_features)\n",
    "\n",
    "# Combinar los nombres de las columnas numéricas y categóricas\n",
    "processed_columns = numeric_features + list(encoded_categorical_columns)\n",
    "\n",
    "# Crear DataFrame con los datos procesados y los nombres de las columnas\n",
    "processed_df = pd.DataFrame(X_processed, columns=processed_columns)\n",
    "concatenated_series  = pd.concat([processed_df, variables_sin_modificacion.reset_index(drop=True) ], axis=1) # En este código, he utilizado reset_index(drop=True) al obtener variables_sin_modificacion para asegurarme de que los índices coincidan correctamente al realizar la concatenación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELO 2 \n",
    "# Metrica_Modelo\tScore\n",
    "# 38\txgbClassifier_recall_macro\t0.868093\n",
    "# 39\txgbClassifier_precision_macro\t0.876113\n",
    "# 37\txgbClassifier_f1_macro\t0.866505\n",
    "# 36\txgbClassifier_accuracy\t0.868107\n",
    "# 46\tSVC_recall_macro\t0.792344\n",
    "# 47\tSVC_precision_macro\t0.793586\n",
    "# 45\tSVC_f1_macro\t0.792119\n",
    "# 44\tSVC_accuracy\t0.792346\n",
    "# 6\tRandom Forest_recall_macro\t0.887075\n",
    "# 7\tRandom Forest_precision_macro\t0.889157\n",
    "# 5\tRandom Forest_f1_macro\t0.886920\n",
    "# 4\tRandom Forest_accuracy\t0.887080\n",
    "# 2\tLogistic Regression_recall_macro\t0.709532\n",
    "# 3\tLogistic Regression_precision_macro\t0.709742\n",
    "# 1\tLogistic Regression_f1_macro\t0.709460\n",
    "# 0\tLogistic Regression_accuracy\t0.709535\n",
    "# 34\tLGBclassifier_recall_macro\t0.874132\n",
    "# 35\tLGBclassifier_precision_macro\t0.886193\n",
    "# 33\tLGBclassifier_f1_macro\t0.871222\n",
    "# 32\tLGBclassifier_accuracy\t0.874148\n",
    "# 42\tKNN_recall_macro\t0.837828\n",
    "# 43\tKNN_precision_macro\t0.845589\n",
    "# 41\tKNN_f1_macro\t0.836924\n",
    "# 40\tKNN_accuracy\t0.837830\n",
    "\n",
    "# ESTE FUE EL PRIMER RESULTADO DEL CROOS-VALIDATION CON LAS FEATURES NUEVAS LOS DATOS BAJARON BASTANTE Y AHORA ANDAMOS PROBANDO CON TODAS\n",
    "\n",
    "# Metrica_Modelo\tScore\n",
    "# 38\txgbClassifier_recall_macro\t0.851940\n",
    "# 39\txgbClassifier_precision_macro\t0.864105\n",
    "# 37\txgbClassifier_f1_macro\t0.848717\n",
    "# 36\txgbClassifier_accuracy\t0.851956\n",
    "# 46\tSVC_recall_macro\t0.750076\n",
    "# 47\tSVC_precision_macro\t0.752073\n",
    "# 45\tSVC_f1_macro\t0.749600\n",
    "# 44\tSVC_accuracy\t0.750079\n",
    "# 6\tRandom Forest_recall_macro\t0.874214\n",
    "# 7\tRandom Forest_precision_macro\t0.877441\n",
    "# 5\tRandom Forest_f1_macro\t0.873911\n",
    "# 4\tRandom Forest_accuracy\t0.874220\n",
    "# 2\tLogistic Regression_recall_macro\t0.666717\n",
    "# 3\tLogistic Regression_precision_macro\t0.667271\n",
    "# 1\tLogistic Regression_f1_macro\t0.666447\n",
    "# 0\tLogistic Regression_accuracy\t0.666721\n",
    "# 34\tLGBclassifier_recall_macro\t0.851155\n",
    "# 35\tLGBclassifier_precision_macro\t0.865236\n",
    "# 33\tLGBclassifier_f1_macro\t0.847113\n",
    "# 32\tLGBclassifier_accuracy\t0.851172\n",
    "# 42\tKNN_recall_macro\t0.822145\n",
    "# 43\tKNN_precision_macro\t0.836495\n",
    "# 41\tKNN_f1_macro\t0.820267\n",
    "# 40\tKNN_accuracy\t0.822147\n",
    "# 18\tHistGradient_recall_macro\t0.845509\n",
    "# 19\tHistGradient_precision_macro\t0.856584\n",
    "# 17\tHistGradient_f1_macro\t0.842516\n",
    "# 16\tHistGradient_accuracy\t0.845524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "def BaseLine(x_train, y_train, cv: int, metricas_cross_validate: list):\n",
    "    try:\n",
    "        modelos = {\n",
    "            \"1\": LogisticRegression(),\n",
    "            \"2\": RandomForestClassifier(),\n",
    "            \"3\": AdaBoostClassifier(),\n",
    "            \"4\": GradientBoostingClassifier(),\n",
    "            \"5\": ExtraTreesClassifier(),\n",
    "            \"6\": DecisionTreeClassifier(),\n",
    "            \"7\": CatBoostClassifier(),\n",
    "            \"8\": LGBMClassifier(),\n",
    "            \"9\": XGBClassifier(),\n",
    "            \"10\": KNeighborsClassifier(),\n",
    "            \"11\": SVC()\n",
    "        }\n",
    "\n",
    "        answer_modelos = input('¿Cuáles son los modelos que desea utilizar? (seleccione números separados por comas o escriba \"todos\" para seleccionar todos los modelos): 1: Logistic Regression, 2: Random Forest, 3: ADABoosting, 4: GradientBoosting, 5: ExtraTrees, 6: DecisionTree, 7: CatBoost, 8: LGBM, 9: XGBoost, 10: KNN, 11: SVC')\n",
    "\n",
    "        if answer_modelos.lower() == 'todos':\n",
    "            modelos_seleccionados = modelos\n",
    "        else:\n",
    "            selected_models_indices = [int(x.strip()) for x in answer_modelos.split(',')]\n",
    "            modelos_seleccionados = {key: modelos[key] for key in map(str, selected_models_indices)}\n",
    "\n",
    "        metricas = metricas_cross_validate\n",
    "\n",
    "        resultados_dict = {}\n",
    "\n",
    "        for nombre_modelo, modelo in modelos_seleccionados.items():\n",
    "            if cv:\n",
    "                cv_resultados = cross_validate(modelo, x_train, y_train, cv=cv, scoring=metricas)\n",
    "            else:\n",
    "                cv_resultados = cross_validate(modelo, x_train, y_train, cv=5, scoring=metricas)\n",
    "\n",
    "            for metrica in metricas:\n",
    "                clave = f\"{nombre_modelo}_{metrica}\"\n",
    "                resultados_dict[clave] = cv_resultados[f\"test_{metrica}\"].mean()\n",
    "\n",
    "        # Y tienes una lista de nombres que quieres usar para reemplazar los números\n",
    "        lista_nombres = ['Logistic_Regression', 'Random_Forest', 'ADABoosting', 'Gradient_Boosting', 'Extra_Trees', 'Decision_Tree', 'CatBoost', 'LGBM', 'XGBoost', 'KNN', 'SVC']\n",
    "\n",
    "        # Utilizamos una comprensión de diccionario para hacer el reemplazo\n",
    "        diccionario_nombres = {key: lista_nombres[int(key) - 1] for key in modelos_seleccionados}\n",
    "\n",
    "        resultados_df = pd.DataFrame(resultados_dict.values(), index=diccionario_nombres.values(), columns=[\"Score\"])\n",
    "        resultados_df.index.name = \"Metrica_Modelo\"\n",
    "\n",
    "        return resultados_df.reset_index().sort_values(by=\"Metrica_Modelo\", ascending=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Surgió un error:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir condiciones y valores correspondientes\n",
    "conditions = [\n",
    "    (df['Age'] >= 18) & (df['Age'] <= 30),\n",
    "    (df['Age'] > 30) & (df['Age'] <= 50),\n",
    "    df['Age'] > 50\n",
    "]\n",
    "\n",
    "values = ['Adulto Joven', 'Adulto', 'Adulto Grande']\n",
    "\n",
    "# Aplicar las condiciones y asignar valores\n",
    "df['Age_group'] = np.select(conditions, values)\n",
    "\n",
    "\n",
    "# Gráfico con segmentación por país y género\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    sns.countplot(data=df, x='Geography', hue='Age_group', palette=['blue', 'pink', 'green'])\n",
    "    plt.xlabel('Países')\n",
    "    plt.ylabel('count')\n",
    "    plt.legend(title='Age_group')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Relación entre los países y el grupo de edad')\n",
    "    plt.show()\n",
    "    \n",
    "# Gráfico con segmentación por país y género\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    sns.countplot(data=df, x='Geography', hue='Gender', palette=['blue', 'pink', 'green'])\n",
    "    plt.xlabel('Países')\n",
    "    plt.ylabel('count')\n",
    "    plt.legend(title='Gender')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Relación entre los países y el género')\n",
    "    plt.show()\n",
    "\n",
    "# Gráfico con segmentación por país y género\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    sns.countplot(data=df, x='Geography', hue='Exited', palette=['blue', 'pink', 'green'])\n",
    "    plt.xlabel('Países')\n",
    "    plt.ylabel('count')\n",
    "    plt.legend(title='Exited')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Relación entre los países y el abandono hacia el Banco')\n",
    "    plt.show()\n",
    "    \n",
    "# Cálculo del porcentaje de abandono por país y género\n",
    "result_3 = df.groupby(['Geography', 'Gender', 'Age_group'])['Exited'].value_counts() / len(df) * 100\n",
    "result_df_3 = result_3.reset_index(name='Porcentaje')\n",
    "print(result_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Tabla de contingencia entre 'Geography' y 'Exited'\n",
    "contingency_table_geo_exited = pd.crosstab(df['Geography'], df['Exited'])\n",
    "\n",
    "# Prueba de chi-cuadrado entre 'Geography' y 'Exited'\n",
    "chi2_geo_exited, p_geo_exited, _, _ = chi2_contingency(contingency_table_geo_exited)\n",
    "\n",
    "# Tabla de contingencia entre 'Gender' y 'Exited'\n",
    "contingency_table_gender_exited = pd.crosstab(df['Gender'], df['Exited'])\n",
    "\n",
    "# Prueba de chi-cuadrado entre 'Gender' y 'Exited'\n",
    "chi2_gender_exited, p_gender_exited, _, _ = chi2_contingency(contingency_table_gender_exited)\n",
    "\n",
    "# Tabla de contingencia entre 'Age_group' y 'Exited'\n",
    "contingency_table_age_exited = pd.crosstab(df['Age_group'], df['Exited'])\n",
    "\n",
    "# Prueba de chi-cuadrado entre 'Age_group' y 'Exited'\n",
    "chi2_age_exited, p_age_exited, _, _ = chi2_contingency(contingency_table_age_exited)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Prueba Chi-cuadrado entre Geography y Exited:\")\n",
    "print(\"Estadístico de Chi-cuadrado:\", chi2_geo_exited)\n",
    "print(\"Valor p:\", p_geo_exited)\n",
    "print(\"\\nPrueba Chi-cuadrado entre Gender y Exited:\")\n",
    "print(\"Estadístico de Chi-cuadrado:\", chi2_gender_exited)\n",
    "print(\"Valor p:\", p_gender_exited)\n",
    "print(\"\\nPrueba Chi-cuadrado entre Age_group y Exited:\")\n",
    "print(\"Estadístico de Chi-cuadrado:\", chi2_age_exited)\n",
    "print(\"Valor p:\", p_age_exited)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
